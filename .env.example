# Translation API Configuration
API_ENDPOINT=http://localhost:11434/api/generate
DEFAULT_MODEL=qwen3:14b

# Server Configuration
PORT=5000  # Port for the web interface
HOST=127.0.0.1  # Server host (127.0.0.1 for localhost only, 0.0.0.0 for all network interfaces)
OUTPUT_DIR=translated_files  # Directory for translated output files

# LLM Provider Settings
# Options: ollama, poe, gemini, openai, openrouter, mistral, deepseek
LLM_PROVIDER=ollama
# Your Google Gemini API key (required if using gemini provider)
GEMINI_API_KEY=
GEMINI_MODEL=gemini-2.0-flash
# Your OpenAI API key (required if using openai provider)
OPENAI_API_KEY=

# OpenRouter Settings (access to 200+ models: Claude, GPT-4, Llama, Mistral, etc.)
# Your OpenRouter API key (from https://openrouter.ai/keys)
OPENROUTER_API_KEY=
OPENROUTER_MODEL=anthropic/claude-4.5-haiku
# See all models at https://openrouter.ai/models (text-only models are auto-filtered in the UI)

# Mistral AI Settings
# Your Mistral API key (from https://console.mistral.ai)
MISTRAL_API_KEY=
MISTRAL_MODEL=mistral-large-latest
# Available models: mistral-large-latest (128K), mistral-medium-latest (128K),
#                   mistral-small-latest (32K), codestral-latest (32K)
# MISTRAL_API_ENDPOINT=https://api.mistral.ai/v1/chat/completions  # Optional, default endpoint

# DeepSeek Settings (Chinese LLM, very cost-effective)
# Get your API key at: https://platform.deepseek.com/
DEEPSEEK_API_KEY=
DEEPSEEK_MODEL=deepseek-chat
# Available models: deepseek-chat (fast, 64K context)
# DEEPSEEK_API_ENDPOINT=https://api.deepseek.com/chat/completions  # Optional, default endpoint

# Poe Settings (Multi-provider access: Claude, GPT, Gemini, Llama, Grok, and more)
# Get your API key at: https://poe.com/api_key
POE_API_KEY=
POE_MODEL=Claude-Sonnet-4
# Popular models: Claude-Sonnet-4, Claude-Opus-4.1, GPT-4o, Gemini-2.5-Pro, Llama-3.1-405B, Grok-4
# Poe also provides access to millions of community-created bots

# Translation Settings
# Source language: Auto-detected from uploaded file (uses langdetect library)
# Target language: Auto-detected from browser language (can be changed in UI)
MAIN_CHUNK_SIZE=1000      # Maximum characters per chunk
REQUEST_TIMEOUT=900       # API timeout in seconds

# Token-based Chunking
# All file types use token-based chunking with tiktoken for consistent chunk sizes
MAX_TOKENS_PER_CHUNK=400          # Maximum tokens per chunk (hard limit)
SOFT_LIMIT_RATIO=0.8              # Start looking for boundaries at 80% of max tokens

# Context Management (IMPORTANT)
# Formula: required_ctx = prompt_tokens + (MAX_TOKENS_PER_CHUNK * 2) + 50
#   - prompt_tokens ≈ 500 (instructions) + MAX_TOKENS_PER_CHUNK (source text)
#   - Response buffer = MAX_TOKENS_PER_CHUNK * 2 (translation can be 2x longer for some languages)
#   - +50 for <Translated> tags
# Examples:
#   - MAX_TOKENS_PER_CHUNK=450 → needs ~2048 context
#   - MAX_TOKENS_PER_CHUNK=700 → needs ~4096 context
#   - MAX_TOKENS_PER_CHUNK=800 → needs ~4096 context
OLLAMA_NUM_CTX=4096

# Automatic Context Optimization
AUTO_ADJUST_CONTEXT=true  # Automatically adjust context/chunk size if prompt too large

# Advanced
MAX_TRANSLATION_ATTEMPTS=3

EPUB_TOKEN_ALIGNMENT_ENABLED=true
# Options: true (enable Phase 2 fallback), false (use old behavior with only Phase 1 + Phase 3)

EPUB_TOKEN_ALIGNMENT_METHOD=proportional
# Options:
#   proportional - Position-based alignment (fast, no dependencies)
#   advanced - Future: ML-based alignment (requires additional libraries)

# SRT-specific configuration
SRT_LINES_PER_BLOCK=20
SRT_MAX_CHARS_PER_BLOCK=2000

# Debug Mode
# Enable verbose logging for troubleshooting configuration and connection issues.
# Set to 'true' to see detailed logs about .env loading, API calls, and configuration values.
# Useful when models are not detected or languages are not applied correctly.
DEBUG_MODE=false

# Translation Signature
# This adds a discrete attribution to your translations (metadata for EPUB, footer for TXT, comment for SRT)
# Please consider keeping this enabled to support the project and help others discover this free tool!
# The signature is non-intrusive and placed at the end of files. Thank you for your support!
SIGNATURE_ENABLED=true

# TTS (Text-to-Speech) Configuration
# Generate audio narration of translated documents
# Requires ffmpeg installed on the system for Opus encoding
TTS_ENABLED=false

# TTS Provider Selection
# Available providers:
#   - edge-tts: Microsoft Edge neural voices (free, cloud-based, no GPU required)
#   - chatterbox: Chatterbox TTS (local, GPU-accelerated, voice cloning support)
TTS_PROVIDER=edge-tts

# Voice selection (leave empty for auto-selection based on target language)
# Edge-TTS examples: zh-CN-XiaoxiaoNeural (Chinese female), zh-CN-YunxiNeural (Chinese male)
# Chatterbox: Uses language codes (e.g., "en", "zh", "fr") - see CHATTERBOX_VOICES below
# See Edge-TTS voices: https://speech.microsoft.com/portal/voicegallery
TTS_VOICE=

# Speech rate adjustment (-50% to +100%, e.g., "+10%", "-20%")
TTS_RATE=+0%
# Opus bitrate for output audio (e.g., 48k, 64k, 96k, 128k)
TTS_BITRATE=64k
# Output format (opus recommended for compact file size)
TTS_OUTPUT_FORMAT=opus

# ===== Chatterbox TTS Configuration =====
# Chatterbox is a GPU-accelerated local TTS with voice cloning capabilities
# GitHub: https://github.com/resemble-ai/chatterbox
# Install: pip install chatterbox-tts torch torchaudio

# GPU/CUDA Requirements:
#   - NVIDIA GPU with CUDA support (recommended: 6GB+ VRAM)
#   - CUDA Toolkit 11.8 or 12.x installed
#   - PyTorch with CUDA support
#   - Falls back to CPU if no GPU available (significantly slower)

# Voice prompt for voice cloning (optional)
# Path to a reference audio file (WAV, MP3, etc.) for voice cloning
# Leave empty to use the default Chatterbox voice
TTS_VOICE_PROMPT_PATH=

# Emotion exaggeration level (0.0 to 1.0)
# 0.0 = neutral/flat, 1.0 = highly expressive
# Default: 0.5 for balanced expressiveness
TTS_EXAGGERATION=0.5

# Classifier-free guidance weight (0.0 to 1.0)
# Higher values = more stable/predictable output
# Lower values = more varied but potentially less consistent
# Default: 0.5 for balanced stability
TTS_CFG_WEIGHT=0.5

# Chatterbox supported languages (23 languages):
# en (English), es (Spanish), fr (French), de (German), it (Italian),
# pt (Portuguese), pl (Polish), tr (Turkish), ru (Russian), nl (Dutch),
# cs (Czech), ar (Arabic), zh (Chinese), ja (Japanese), hu (Hungarian),
# ko (Korean), hi (Hindi), vi (Vietnamese), sv (Swedish), da (Danish),
# fi (Finnish), id (Indonesian), el (Greek)


